{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Homework 1 Part B </h2>\n",
    "<i> Gawan Dekker 11025654, Marvin Lau 12364282, Bobbie van Gorp 11161108</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Implementation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from random import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate input\n",
    "\n",
    "def gen_input_unsorted(length, n):\n",
    "    out = []\n",
    "    out.append([0] * length)\n",
    "    for i in range(length):\n",
    "        for j in range(1, n):\n",
    "            affix = [0] * i + [j]\n",
    "            suffixes = gen_input_unsorted(length - (i + 1), n)\n",
    "            for suffix in suffixes:\n",
    "                out.append(affix + suffix)\n",
    "    return out\n",
    "\n",
    "def gen_input(length, n):\n",
    "    if length > 0:\n",
    "        out = gen_input_unsorted(length, n)\n",
    "        out.sort()\n",
    "    else:\n",
    "        out = []\n",
    "    return out\n",
    "\n",
    "def gen_input_pairs(length, n):\n",
    "    out = gen_input(length * 2, n)\n",
    "    for i in range(len(out)):\n",
    "        out[i] = (out[i][:length], out[i][length:])\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_conflicts(n, length, _in=[], ordered=False):\n",
    "    if (len(_in) < length and n <= length):\n",
    "        out = []\n",
    "        # Add all possible conflicts.\n",
    "        for i in [x for x in range(1, n + 1) if x not in _in]:\n",
    "            out += get_conflicts(n, length, _in + [i], ordered)\n",
    "            if ordered:\n",
    "                break\n",
    "        # Add absence of a conflict if possible.\n",
    "        if (length - len(_in) > n - sum([1 for i in _in if i != 0])):\n",
    "            out += get_conflicts(n, length, _in + [0], ordered)\n",
    "        return out\n",
    "    else:\n",
    "        return [_in]\n",
    "\n",
    "def add_conflicts(pair):\n",
    "    out = []\n",
    "    # Add all possible id conflicts to input pair.\n",
    "    for n in range(len(pair[0]) + 1):\n",
    "        for ids0 in get_conflicts(n, len(pair[0]), ordered=True):\n",
    "            ranking0 = list(zip(pair[0], ids0))\n",
    "            for ids1 in get_conflicts(n, len(pair[0])):\n",
    "                out.append((ranking0, list(zip(pair[1], ids1))))\n",
    "    # Remove any pairs in which conflicts appear\n",
    "    # where relevance grades do not match.\n",
    "    for i in range(len(out) - 1, -1, -1):\n",
    "        delete = False\n",
    "        for r0, id0 in out[i][0]:\n",
    "            if id0 > 0:\n",
    "                for r1, id1 in out[i][1]:\n",
    "                    if id0 == id1 and not r0 == r1:\n",
    "                        delete = True\n",
    "                        break\n",
    "            if delete:\n",
    "                out.pop(i)\n",
    "                break\n",
    "    return out\n",
    "\n",
    "\n",
    "def ERR(g_list, R_func=lambda g, max_g: float(2**g- 1) / 2**max_g):\n",
    "    p = 1\n",
    "    ERR = 0\n",
    "    max_g = max(g_list)\n",
    "    for r in range(1, len(g_list) + 1):\n",
    "        R = R_func(g_list[r - 1], max_g)\n",
    "        ERR += p * R / float(r)\n",
    "        p *= 1 - R\n",
    "    return ERR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interleaving\n",
    "\n",
    "def td_interleaving(ranking_pair,max_interleav=3):\n",
    "    ranking_p = ranking_pair[0] #[(0,0),(0,0),(0,0)] form or duplicate [(0,1),(0,0),(0,0)]\n",
    "    ranking_e = ranking_pair[1]\n",
    "    interleaved = []\n",
    "\n",
    "    p_team = 0 #Amount results assigned from p\n",
    "    e_team = 0\n",
    "    p_pointer = 0 #Next top result from ranking p\n",
    "    e_pointer = 0\n",
    "    found_duplicates = [] #Duplicate documents have an ID of greater than 0. A matching number is an duplciate\n",
    "    limit = len(ranking_p)\n",
    "\n",
    "    while len(interleaved) < max_interleav:\n",
    "\n",
    "        p_priority = np.random.choice(2, 1)[0]\n",
    "        new_result = False\n",
    "        if (p_team < e_team) or (p_team == e_team and p_priority == 1):\n",
    "\n",
    "            while not new_result:\n",
    "                top_result_p = ranking_p[p_pointer]\n",
    "                relevance_p, duplicate_id_p = top_result_p\n",
    "\n",
    "                p_pointer += 1\n",
    "                if duplicate_id_p not in found_duplicates:\n",
    "                    new_result = True\n",
    "                    break\n",
    "                elif p_pointer == limit:\n",
    "                    break\n",
    "\n",
    "            if new_result:\n",
    "                interleaved.append((relevance_p, 0))\n",
    "                p_team += 1\n",
    "\n",
    "                if duplicate_id_p > 0:\n",
    "                    found_duplicates.append(duplicate_id_p)\n",
    "        else:\n",
    "\n",
    "            while not new_result:\n",
    "                top_result_e = ranking_e[e_pointer]\n",
    "                relevance_e, duplicate_id_e = top_result_e\n",
    "                e_pointer += 1\n",
    "\n",
    "                if duplicate_id_e not in found_duplicates:\n",
    "                    new_result = True\n",
    "                    break\n",
    "                elif e_pointer == limit:\n",
    "                    break\n",
    "\n",
    "            if new_result:\n",
    "                interleaved.append((relevance_e, 1))\n",
    "                e_team += 1\n",
    "\n",
    "                if duplicate_id_e > 0:\n",
    "                    found_duplicates.append(duplicate_id_e)\n",
    "\n",
    "    return interleaved\n",
    "\n",
    "def get_softmax(ranking_indices,tau=3):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    numerator_list = [] #Numerator values for each of the ranked results\n",
    "    softmax_distribution = []\n",
    "\n",
    "    for rank_index in ranking_indices:\n",
    "        rank = rank_index + 1\n",
    "        numerator_value = 1/(rank**tau)\n",
    "        numerator_list.append(numerator_value)\n",
    "\n",
    "    denominator = sum(numerator_list)\n",
    "\n",
    "    for value in numerator_list:\n",
    "        probability = value/denominator\n",
    "        softmax_distribution.append(probability)\n",
    "\n",
    "    return softmax_distribution\n",
    "\n",
    "def prob_interleaving(ranking_pair,max_interleav=3):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    ranking_p = ranking_pair[0] #[(0,0),(0,0),(0,0)] form or duplicate [(0,1),(0,0),(0,0)]\n",
    "    ranking_e = ranking_pair[1] #[(0,0),(0,0),(0,0)] form or duplicate #[(0,1),(0,0),(0,0)]\n",
    "    interleaved = []\n",
    "    limit = len(ranking_p)\n",
    "\n",
    "    p_indices = list(range(limit))\n",
    "    e_indices = list(range(limit))\n",
    "\n",
    "    found_duplicates = []\n",
    "\n",
    "    while len(interleaved) < max_interleav:\n",
    "\n",
    "        p_priority = np.random.choice(2, 1)[0]\n",
    "\n",
    "        if (p_priority and len(p_indices) > 0) or len(e_indices) == 0:\n",
    "            softmax_p = get_softmax(p_indices)\n",
    "            doc_index_p = np.random.choice(p_indices, 1, p=softmax_p)[0]\n",
    "            p_indices.remove(doc_index_p)\n",
    "\n",
    "            result_p = ranking_p[doc_index_p]\n",
    "            relevance_p, duplicate_id_p = result_p\n",
    "\n",
    "            if duplicate_id_p == 0 :\n",
    "                interleaved.append((relevance_p, 0))\n",
    "            elif (duplicate_id_p > 0 and duplicate_id_p not in found_duplicates):\n",
    "                interleaved.append((relevance_p, 0))\n",
    "                found_duplicates.append(duplicate_id_p)\n",
    "                duplicate_index = ranking_e.index(result_p)\n",
    "                e_indices.remove(duplicate_index)\n",
    "        else:\n",
    "            softmax_e = get_softmax(e_indices)\n",
    "            doc_index_e = np.random.choice(e_indices, 1, p=softmax_e)[0]\n",
    "            e_indices.remove(doc_index_e)\n",
    "\n",
    "            result_e = ranking_e[doc_index_e]\n",
    "            relevance_e, duplicate_id_e = result_e\n",
    "\n",
    "            if duplicate_id_e == 0:\n",
    "                interleaved.append((relevance_e, 1))\n",
    "            elif (duplicate_id_e > 0 and duplicate_id_e not in found_duplicates):\n",
    "                interleaved.append((relevance_e, 1))\n",
    "                found_duplicates.append(duplicate_id_e)\n",
    "                duplicate_index = ranking_p.index(result_e)\n",
    "                p_indices.remove(duplicate_index)\n",
    "\n",
    "    return interleaved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click Model\n",
    "\n",
    "def read_yandex(path, n=-1):\n",
    "    out = []\n",
    "    with open(path) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            if n >= 0 and i > n:\n",
    "                break\n",
    "            data = l.strip().split('\\t')\n",
    "            item = {\n",
    "                'id'   : int(data[0]),\n",
    "                't'    : int(data[1]),\n",
    "                'a'    : data[2].lower(),\n",
    "                'a_id' : int(data[3])\n",
    "            }\n",
    "            if item['a'] == 'q':\n",
    "                item['r_id'] = int(data[4])\n",
    "                item['urls'] = [int(x) for x in data[5:]]\n",
    "            out.append(item)\n",
    "    return out\n",
    "\n",
    "\n",
    "class RCM:\n",
    "    def __init__(self):\n",
    "        self.rho = random()\n",
    "    \n",
    "    def learn(self, database):\n",
    "        n_clicks, n_docs = 0, 0\n",
    "        for item in database:\n",
    "            if item['a'] == 'q':\n",
    "                n_docs += len(item['urls'])\n",
    "            else:\n",
    "                n_clicks += 1\n",
    "        self.rho = n_clicks / float(n_docs)\n",
    "        return\n",
    "    \n",
    "    def get_p(self, relevance_grades):\n",
    "        out = [self.rho for _ in range(len(relevance_grades))]\n",
    "        return out\n",
    "    \n",
    "    def get_clicks(self, relevance_grades):\n",
    "        p = self.get_p(relevance_grades)\n",
    "        out = []\n",
    "        for i in range(len(p)):\n",
    "            if random() <= p[i]:\n",
    "                out.append(i)\n",
    "        return out\n",
    "\n",
    "\n",
    "class PBM:\n",
    "    def __init__(self):\n",
    "        self.alphas = {}\n",
    "        self.gammas = []\n",
    "    \n",
    "    def update(self, item, alpha_sum, gamma_sum, prev_q, clicks, n=-1):\n",
    "        if item['a'] == 'q':\n",
    "            q_id = prev_q['a_id']\n",
    "            q_urls = prev_q['urls']\n",
    "            if n >= 0:\n",
    "                q_urls = q_urls[:n]\n",
    "            gamma_length = len(q_urls)\n",
    "            # Extend gammas and gamma_sum.\n",
    "            while len(self.gammas) < gamma_length:\n",
    "                self.gammas.append(random())\n",
    "            while len(gamma_sum) < gamma_length:\n",
    "                gamma_sum.append(0)\n",
    "            for r, _id in enumerate(q_urls):\n",
    "                uq = str((_id, q_id))\n",
    "                # Extend alphas and alpha_sum.\n",
    "                if self.alphas.get(uq) == None:\n",
    "                    self.alphas[uq] = random()\n",
    "                if alpha_sum.get(uq) == None:\n",
    "                    alpha_sum[uq] = {'sum' : 0, 'length' : 0}\n",
    "                # Update alphs_sum and gamma_sum.\n",
    "                if _id in clicks:\n",
    "                    alpha_sum[uq]['sum'] += 1\n",
    "                    gamma_sum[r] += 1\n",
    "                else:\n",
    "                    alpha_sum[uq]['sum'] += \\\n",
    "                        (1 - self.gammas[r]) * self.alphas[uq] \\\n",
    "                        / (1 - self.gammas[r] * self.alphas[uq])\n",
    "                    gamma_sum[r] += \\\n",
    "                        self.gammas[r] * (1 - self.alphas[uq]) \\\n",
    "                        / (1 - self.gammas[r] * self.alphas[uq])\n",
    "                alpha_sum[uq]['length'] += 1\n",
    "            prev_q = item\n",
    "            clicks = []\n",
    "        else:\n",
    "            # Record clicked document id.\n",
    "            clicks.append(item['a_id'])\n",
    "        return alpha_sum, gamma_sum, prev_q, clicks\n",
    "    \n",
    "    def _learn(self, database, n=-1):\n",
    "        alpha_sum = {}\n",
    "        gamma_sum = []\n",
    "        prev_q = database[0]\n",
    "        session_id = prev_q['id']\n",
    "        clicks = []\n",
    "        \n",
    "        empty_q = {'id' : -1, 'a' : 'q', 'a_id' : -1, 'urls' : []}\n",
    "        \n",
    "        # Adjust query counter for empty query.\n",
    "        n_queries = 0\n",
    "        if prev_q['a'] != 'q':\n",
    "            n_queries -= 1\n",
    "        \n",
    "        # Sum alpha and gamma contributions\n",
    "        # of each item in the database.\n",
    "        for item in database[1:] + [empty_q]:\n",
    "            if item['a'] == 'q':\n",
    "                n_queries += 1\n",
    "            if session_id != item['id']:\n",
    "                alpha_sum, gamma_sum, prev_q, clicks = self.update(\n",
    "                    empty_q, alpha_sum, gamma_sum, prev_q, clicks, n)\n",
    "                session_id = item['id']\n",
    "            alpha_sum, gamma_sum, prev_q, clicks = self.update(\n",
    "                item, alpha_sum, gamma_sum, prev_q, clicks, n)\n",
    "        \n",
    "        # Update alphas and gammas.\n",
    "        for uq, alpha in alpha_sum.items():\n",
    "            self.alphas[uq] = (alpha['sum'] + 1) \\\n",
    "                / float(alpha['length'] + 2)\n",
    "        for r, gamma_sum_r in enumerate(gamma_sum):\n",
    "            self.gammas[r] = (gamma_sum_r + 1) / float(n_queries + 1)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def learn(self, database, n_decimals, n_consecutive, n_rank=-1):\n",
    "        prev_gammas = []\n",
    "        convergence = False\n",
    "        while convergence == False:\n",
    "            self._learn(database, n_rank)\n",
    "            prev_gammas.append(\n",
    "                [round(gamma, n_decimals) for gamma in self.gammas])\n",
    "            if len(prev_gammas) >= n_consecutive:\n",
    "                while len(prev_gammas) > n_consecutive:\n",
    "                    prev_gammas.pop(0)\n",
    "                convergence = True\n",
    "                for prev, cur in zip(prev_gammas[:-1], prev_gammas[1:]):\n",
    "                    for gamma_prev, gamma_cur in zip(prev, cur):\n",
    "                        if gamma_prev - gamma_cur != 0:\n",
    "                            convergence = False\n",
    "                            break\n",
    "                    if convergence == False:\n",
    "                        break\n",
    "        return\n",
    "    \n",
    "    def get_p(self, relevance_grades, epsilon=1e-1):\n",
    "        out = []\n",
    "        for i in range(min(len(self.gammas), len(relevance_grades))):\n",
    "            if relevance_grades[i] == 0:\n",
    "                out.append(self.gammas[i] * epsilon)\n",
    "            else:\n",
    "                out.append(self.gammas[i] * (1 - epsilon))\n",
    "        return out\n",
    "    \n",
    "    def get_clicks(self, relevance_grades, epsilon=1e-1):\n",
    "        p = self.get_p(relevance_grades)\n",
    "        out = []\n",
    "        for i in range(len(p)):\n",
    "            if random() <= p[i]:\n",
    "                out.append(i)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Documentation </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Generate Input </h3>\n",
    "<ul>\n",
    "<li>gen_input_unsorted(length, n) <br>\n",
    "    Creates a list of all possible combinations of relevance scores.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    length : int\n",
    "        Length of a combination of relevance scores.\n",
    "    n : int\n",
    "        Maximum relevance score\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : list\n",
    "        A list containing all possible combinations of relevance scores.\n",
    "    \n",
    "\n",
    "</li>\n",
    "\n",
    "<li>gen_input(length, n) <br>\n",
    "    Creates a sorted list of all possible combinations\n",
    "    of relevance scores.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    length : int\n",
    "        Length of a combination of relevance scores.\n",
    "    n : int\n",
    "        Maximum relevance score\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : list\n",
    "        A sorted list containing all possible combinations\n",
    "        of relevance scores.\n",
    "\n",
    "    \n",
    "</li>\n",
    "\n",
    "<li>     gen_input_pairs(length, n) <br>\n",
    "    Creates a sorted list of all possible pairs of combinations\n",
    "    of relevance scores.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    length : int\n",
    "        Length of a combination of relevance scores.\n",
    "    n : int\n",
    "        Maximum relevance score\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : list\n",
    "        A sorted list containing all possible pairs of combinations\n",
    "        of relevance scores.\n",
    "</li>\n",
    "\n",
    "<li>get_conflicts(n, length, _in=[], ordered=False) <br>\n",
    "    Creates a list of all possible id conflicts.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Total possible number of id conflicts at a time.\n",
    "    length: int\n",
    "        Length of the list containing id conflicts.\n",
    "    _in : array_like\n",
    "        Array of current id conflicts.\n",
    "    ordered : bool\n",
    "        Indicates whether id conflict numbers are to appear in order\n",
    "        or are permitted to appear in any order.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : list\n",
    "        A list containing all possible id conflicts.\n",
    "        A value of 0 indicates no conflict,\n",
    "        a value higher than indicates a conflict.\n",
    "\n",
    "    \n",
    "</li>\n",
    "\n",
    "<li>add_conflicts(pair) <br>\n",
    "    Adds id conflicts to a tuple of combinations of relevance grades.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pair : tuple\n",
    "        Tuple of combinations of relevance grades.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : list\n",
    "        A list of all possible tuples of combinations\n",
    "        of relevance grades with id conflicts.\n",
    "        Relevance grades from the inputs have been replaced by a tuple\n",
    "        of relevance grade and id conflict number.\n",
    "    \n",
    "    \n",
    "</li>\n",
    "\n",
    "<li>ERR(g_list, R_func=lambda g, max_g: float(2**g- 1) / 2**max_g) <br>\n",
    "    Calculates Expected Reciprocal Rank for one list\n",
    "    of relevance grades.\n",
    "    \n",
    "    Source\n",
    "    ------\n",
    "    The algorithm originates from a paper by O. Chapelle et al.\n",
    "    named \"Expected Reciprocal Rank for Graded Relevance\"\n",
    "    and can be found here: http://olivier.chapelle.cc/pub/err.pdf\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    g_list : array_like\n",
    "        Array of relevance grades.\n",
    "    R_func : function(int, int) -> float\n",
    "        Function that converts a relevance grade\n",
    "        to probability of relevance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ERR : float\n",
    "        Expected Reciprocal Rank.\n",
    "    \n",
    "    \n",
    "</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Interleaving </h3>\n",
    "<ul>\n",
    "<li>td_interleaving(ranking_par,max_interleav=3) <br>\n",
    "Run Team-draft interleaving given a ranking pair as input\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    An ranking pair : List of ranked and labeled results\n",
    "        Index of list elements represents the rank of that element. Each\n",
    "        element is a tuple of the relevance score and a duplicate ID.\n",
    "        If this value is 0, it has no duplicate with a document in the results of other ranker.\n",
    "        If the value is greater than 0, then it has a duplicate with another result of the other ranker that matches this number\n",
    "        No duplicate example: E ranked list:  [(0,0),(0,0),(0,0)] and P ranked list: [(1,0),(0,0),(0,0)] form\n",
    "        2 duplicates example: E ranked list: [(1,1),(0,2),(0,0)]  and P ranked list: [(1,0),(1,1),(0,2)]  for example\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Interleaved list (of length 3 as default) based on Team-draft method: list\n",
    "        Index + 1 represents the rank of the interleaved list and element is an tuple of the form (relevance: binary,ranker credit:binary), Credits are assigned as P(0) and E(1)\n",
    "</li>        \n",
    "        \n",
    "<li> get_softmax(ranking_indices,tau=3)<br>\n",
    "    Compute softmax distribution for a ranker given the indices of documents that are avaliable to be picked.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Ranking indices : List of indices that represent the rank of documents that can be picked for next interleaving.\n",
    "    Example of nothing picked of ranker: List of the form: [0,1,2]\n",
    "    Example of document already picked of ranker: List of the form: [0,2]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List of softmax probabilities for documents to be picked: List\n",
    "        The list maps one to one the ranking indices that were given as input, each element is a probability for the document for that particular index\n",
    "        in that ranking indices list, which in turn consist of numbers that represents the actual indices to be picked from ranked results.\n",
    "</li>\n",
    "\n",
    "<li> prob_interleaving(ranking_pair,max_interleav=3)<br>\n",
    "    Run Probabilistic interleaving  given a ranking pair as input\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    An ranking pair : List of ranked and labeled results\n",
    "        Index of list elements represents the rank of that element. Each\n",
    "        element is a tuple of the relevance score and a duplicate ID.\n",
    "        If this value is 0, it has no duplicate with a document in the results of other ranker.\n",
    "        If the value is greater than 0, then it has a duplicate with another result of the other ranker that matches this number\n",
    "        No duplicate example: E ranked list:  [(0,0),(0,0),(0,0)] and P ranked list: [(1,0),(0,0),(0,0)] form\n",
    "        2 duplicates example: E ranked list: [(1,1),(0,2),(0,0)]  and P ranked list: [(1,0),(1,1),(0,2)]  for example\n",
    "    Returns\n",
    "    -------\n",
    "    Interleaved list (of length 3 as default) based on probabilistc interleaving method: list\n",
    "        Index + 1 represents the rank of the interleaved list and element is an tuple of the form (relevance: binary,ranker credit:binary), credits are assigned as P(0) and E(1)\n",
    "    \n",
    "    \n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Click Model </h3>\n",
    "<ul>\n",
    "<li> read_yandex(path, n=-1) <br>\n",
    "    Reads yandex database.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to database file.\n",
    "    n : int\n",
    "        Number of lines to read. Is ignored if value is lower than 0.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : list\n",
    "        A list of dictionaries representing database entries.\n",
    "    \n",
    "   \n",
    "</li>\n",
    "\n",
    "<li> <h4> Class RCM </h4>\n",
    "    \n",
    "    Random Click Model\n",
    "    ==================\n",
    "    \n",
    "    Click model that simulates user interaction as random clicking.\n",
    "    \n",
    "    One parameter `rho` is learned signifying the chance\n",
    "    of a document being clicked. User interaction is then simulated\n",
    "    by comparing a random value drawn from a uniform distribution\n",
    "    against this `rho` value. `Rho` is initialized when an instance\n",
    "    of the class is created.\n",
    "    \n",
    "    \n",
    " Methods of this class: <br><br>\n",
    "<ul>\n",
    "\n",
    "<li> learn(self, database) <br>\n",
    "        Learns class parameters.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        database : array_like\n",
    "            Array of dictionaries representing database items.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "    \n",
    "</li>\n",
    "\n",
    "<li> get_p(self, relevance_grades) <br>\n",
    "        Determines chance of clicking on a document.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        relevance_grades : array_like\n",
    "            Array containing relevance grades for all documents\n",
    "            returned by a search query.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out : list\n",
    "            List of probabilities corresponding\n",
    "            to entries in `search_results`.\n",
    "        \n",
    "    \n",
    "</li>\n",
    "\n",
    "<li> get_clicks(self, relevance_grades) <br>\n",
    "        Simulate user interaction by determining\n",
    "        what documents are clicked on.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        relevance_grades : array_like\n",
    "            Array containing relevance grades for all documents\n",
    "            returned by a search query.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out : list\n",
    "            List of indices of the documents that were clicked on\n",
    "            in the simulation.\n",
    "    \n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "<li> <h4> Class PBM </h4>\n",
    "    \n",
    "    Position Based Click Model\n",
    "    ==========================\n",
    "    \n",
    "    Click model that simulates user interaction\n",
    "    based on rank and document score.\n",
    "    \n",
    "    Two sets of parameters are learned, `alphas` and `gammas`.\n",
    "    Parameters in `alphas` represent the attractiveness of documents\n",
    "    given a certain query, while parameters in `gammas` represent\n",
    "    the chance of viewing a document at a specific rank.\n",
    "    User interaction is simulated by comparing a random value\n",
    "    drawn from a uniform distribution against the product of\n",
    "    one of the parameters in `gammas` and a value `epsilon`.\n",
    "    Here `epsilon` represents the chance of clicking on a document\n",
    "    even though the document is irrelevant and vice versa (`epsilon` replaces\n",
    "    the parameters in `alpha` due to data sparcity).\n",
    "    \n",
    "    \n",
    "   Methods of this class: <br><br>\n",
    "<ul>\n",
    "\n",
    "<li> update(self, item, alpha_sum, gamma_sum, prev_q, clicks, n=-1) <br>\n",
    "        Updates sum of alpha and gamma contributions\n",
    "        for the previous query database item.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        item : dict\n",
    "            A dictionary representing a database item.\n",
    "        alpha_sum : dict\n",
    "            A dictionary containing the summed contributions and\n",
    "            number of contributions for all alphas corresponding\n",
    "            to a document and query pair.\n",
    "        gamma_sum : array_like\n",
    "            A list containing the summed contributions of all gammas\n",
    "            corresponding to a rank.\n",
    "        prev_q : dict\n",
    "            A dictionary representing the previous query database item.\n",
    "        clicks : array_like\n",
    "            A list of documents ids, returned by the last query,\n",
    "            that the user clicked on.\n",
    "        n : int\n",
    "            Maximum rank for which parameters are learned.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        alpha_sum : dict\n",
    "            A dictionary containing the summed contributions and\n",
    "            number of contributions for all parameters in `alphas`\n",
    "            corresponding to a document and query pair.\n",
    "        gamma_sum : array_like\n",
    "            A list containing the summed contributions for all\n",
    "            parameters in `gammas` corresponding to a rank.\n",
    "        prev_q : dict\n",
    "            A dictionary representing the previous query database item.\n",
    "        clicks : array_like\n",
    "            A list of documents ids, returned by the last query,\n",
    "            that the user clicked on.\n",
    "    \n",
    "</li>\n",
    "\n",
    "<li> _learn(self, database, n=-1) <br>\n",
    "        Learns class parameters for one run over the given database.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        database : array_like\n",
    "            Array of dictionaries representing database items.\n",
    "        n : int\n",
    "            Maximum rank for which parameters are learned.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "\n",
    "    \n",
    "</li>\n",
    "\n",
    "<li> learn(self, database, n_decimals, n_consecutive, n_rank=-1) <br>\n",
    "        Learns class parameters on the given database\n",
    "        until convergence.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        database : array_like\n",
    "            Array of dictionaries representing database items.\n",
    "        n_decimals : int\n",
    "            Number of decimals on which convergence is checked.\n",
    "        n_consecutive : int\n",
    "            Number of consecutive database iterations for which\n",
    "            convergence is checked.\n",
    "        n_rank : int\n",
    "            Maximum rank for which parameters are learned.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \n",
    "    \n",
    "</li>\n",
    "\n",
    "<li> get_p(self, relevance_grades, epsilon=1e-1) <br>\n",
    "        Determines chance of clicking on a document.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        relevance_grades : array_like\n",
    "            Array containing relevance grades for all documents\n",
    "            returned by a search query.\n",
    "        epsilon : float\n",
    "            Value representing the chance of clicking on a document\n",
    "            even though the document is irrelevant and vice versa.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out : list\n",
    "            List of probabilities corresponding\n",
    "            to entries in `search_results`.\n",
    "    \n",
    "</li>\n",
    "\n",
    "<li> get_clicks(self, relevance_grades, epsilon=1e-1) <br>\n",
    "        Simulate user interaction by determining\n",
    "        what documents are clicked on.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        relevance_grades : array_like\n",
    "            Array containing relevance grades for all documents\n",
    "            returned by a search query.\n",
    "        epsilon : float\n",
    "            Value representing the chance of clicking on a document\n",
    "            even though the document is irrelevant and vice versa.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out : list\n",
    "            List of indices of the documents that were clicked on\n",
    "            in the simulation.\n",
    "    \n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Analysis </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
